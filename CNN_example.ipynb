{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9_L6KwlJ17E"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfLaJ196AqdH"
   },
   "outputs": [],
   "source": [
    "#데이터를 불러옵니다.\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxzRenhuSmJx"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rw1MyAzgSxF4",
    "outputId": "21126036-43b8-4399-db30-68ec15ec0e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "Bv7wDfYCSoNQ",
    "outputId": "0e604f9a-c3c0-4e0a-91bb-0caa8ee9cf6a",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "DisabledFunctionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f4cdcfc1e8f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
     ]
    }
   ],
   "source": [
    "#데이터를 확인합니다(colab의 경우 cv2.imshow가 실행이 안되어 plt.imshow를 사용하시면 됩니다.)\n",
    "cv2.imshow(X_train[0],cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GCFEGg0gt2A"
   },
   "outputs": [],
   "source": [
    "#위에서 shape을 확인한 결과 (60000,28,28)로 각 이미지는 2차원 데이터입니다.\n",
    "#CNN은 가로x세로x채널의 3차원의 이미지를 사용하므로 input이미지를 4차원 데이터로 바꾸어줍니다(이미지=3차원, 그 이미지들 묶으니까 차원 하나 더 추가)\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "\n",
    "#정답의 경우 categorical이기에 해당 변수로 변환합니다.\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "#0~255사이의 값을 갖는 픽셀들을 0~1의 값을 가지도록 변환시킵니다.\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "random_seed = 2\n",
    "#train set을 다시 train과 validation으로 나누어 줍니다.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "brto4XbdHgey",
    "outputId": "3209a61a-495f-4a71-e439-340e87488754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f68bd84f828>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD7CAYAAAClmULcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3YbZ3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "YzOc8_RZPDho",
    "outputId": "9d249e06-b11f-41ca-fbfd-25993f7b9e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "#저는 keras로 진행합니다.\n",
    "def build_model():\n",
    "    #이 모델이 sequential한 모델임을 선언합니다(그냥 쭉 직선, 발표 ppt에 googleNet의 경우가 예외)\n",
    "    model = Sequential()\n",
    "    #Convolution Layer를 추가합니다. 이 Layer에는 산출하는 Activation map의 갯수, 사용하는 filter의 크기, padding, stride를 설정하며\n",
    "    #추가적으로 Activation function, weight initializer를 추가할 수 있습니다.\n",
    "    model.add(Conv2D(filters=16, kernel_size=(1,1),input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(filters=16, kernel_size=(1,1)))\n",
    "    model.add(Conv2D(filters=16, kernel_size=(1,1)))\n",
    "    #pooling layer를 추가합니다.\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #feature extraction을 마쳤으므로 이를 MLP에 넣기위해 데이터를 flatten시킵니다. 즉 image의 shape를 3차원 -> 1차원으로 변경합니다.\n",
    "    model.add(Flatten())\n",
    "    #이후는 기존에 진행했던 MLP구조와 같습니다.\n",
    "    model.add(Dense(128, activation='relu',kernel_initializer='he_normal'))\n",
    "    #예측값이 1~10의 10개이므로 output을 10개로 설정합니다. 이를 softmax를 거치게합니다.\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    #optimizer로 adam을 사용하고 사용하는 loss값은 cross entropy입니다. 학습하며 accuracy도 같이 봅니다만 이는 학습에 영향을 미치지 않습니다.\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-l49F3qcSYD"
   },
   "outputs": [],
   "source": [
    "#이미지 학습에서 중요한 요소 중 하나는 augumentation입니다. 이미지를 좌,우로 반전시키거나, 회전하거나, 확대시킵니다.\n",
    "#즉 배치마다 데이터의 모양이 달라집니다. 그리고 데이터를 더 많이 넣을 수도 있습니다.\n",
    "#이 내용은 세션 내용에는 없지만 너무 중요한 부분이라 넣었습니다.\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aBLeGVvnPNrX",
    "outputId": "cd89b50e-178c-467d-8a6b-612eb6693e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.6511 - acc: 0.8014 - val_loss: 0.1023 - val_acc: 0.9728\n",
      "Epoch 2/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.2092 - acc: 0.9388 - val_loss: 0.0554 - val_acc: 0.9830\n",
      "Epoch 3/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.1538 - acc: 0.9548 - val_loss: 0.0642 - val_acc: 0.9787\n",
      "Epoch 4/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.1206 - acc: 0.9644 - val_loss: 0.0361 - val_acc: 0.9887\n",
      "Epoch 5/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.1056 - acc: 0.9694 - val_loss: 0.0446 - val_acc: 0.9867\n",
      "Epoch 6/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0953 - acc: 0.9722 - val_loss: 0.0297 - val_acc: 0.9907\n",
      "Epoch 7/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0847 - acc: 0.9755 - val_loss: 0.0244 - val_acc: 0.9932\n",
      "Epoch 8/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0791 - acc: 0.9769 - val_loss: 0.0385 - val_acc: 0.9855\n",
      "Epoch 9/30\n",
      "843/843 [==============================] - 18s 21ms/step - loss: 0.0772 - acc: 0.9786 - val_loss: 0.0225 - val_acc: 0.9922\n",
      "Epoch 10/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0731 - acc: 0.9790 - val_loss: 0.0305 - val_acc: 0.9900\n",
      "Epoch 11/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0687 - acc: 0.9802 - val_loss: 0.0202 - val_acc: 0.9930\n",
      "Epoch 12/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0663 - acc: 0.9817 - val_loss: 0.0243 - val_acc: 0.9915\n",
      "Epoch 13/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0608 - acc: 0.9824 - val_loss: 0.0190 - val_acc: 0.9942\n",
      "Epoch 14/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0609 - acc: 0.9823 - val_loss: 0.0194 - val_acc: 0.9938\n",
      "Epoch 15/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0593 - acc: 0.9826 - val_loss: 0.0202 - val_acc: 0.9938\n",
      "Epoch 16/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0549 - acc: 0.9835 - val_loss: 0.0292 - val_acc: 0.9908\n",
      "Epoch 17/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0513 - acc: 0.9852 - val_loss: 0.0217 - val_acc: 0.9945\n",
      "Epoch 18/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0515 - acc: 0.9848 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "Epoch 19/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0507 - acc: 0.9854 - val_loss: 0.0192 - val_acc: 0.9935\n",
      "Epoch 20/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0490 - acc: 0.9858 - val_loss: 0.0145 - val_acc: 0.9943\n",
      "Epoch 21/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0471 - acc: 0.9861 - val_loss: 0.0179 - val_acc: 0.9940\n",
      "Epoch 22/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0474 - acc: 0.9862 - val_loss: 0.0169 - val_acc: 0.9938\n",
      "Epoch 23/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0445 - acc: 0.9866 - val_loss: 0.0174 - val_acc: 0.9945\n",
      "Epoch 24/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0477 - acc: 0.9862 - val_loss: 0.0199 - val_acc: 0.9932\n",
      "Epoch 25/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0426 - acc: 0.9878 - val_loss: 0.0187 - val_acc: 0.9935\n",
      "Epoch 26/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0419 - acc: 0.9883 - val_loss: 0.0180 - val_acc: 0.9945\n",
      "Epoch 27/30\n",
      "843/843 [==============================] - 18s 22ms/step - loss: 0.0406 - acc: 0.9887 - val_loss: 0.0168 - val_acc: 0.9947\n",
      "Epoch 28/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0381 - acc: 0.9887 - val_loss: 0.0163 - val_acc: 0.9948\n",
      "Epoch 29/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0400 - acc: 0.9879 - val_loss: 0.0193 - val_acc: 0.9938\n",
      "Epoch 30/30\n",
      "843/843 [==============================] - 19s 22ms/step - loss: 0.0375 - acc: 0.9892 - val_loss: 0.0151 - val_acc: 0.9952\n"
     ]
    }
   ],
   "source": [
    "#Image generator를 사용하며 학습시키는 경우 model.fit이 아니라 model.fit_generator를 사용합니다.\n",
    "#아래의 결과는 위의 예제코드의 결과가 아닙니다!!!\n",
    "results = model.fit_generator(datagen.flow(X_train,Y_train,batch_size=64), \n",
    "                    epochs=30,validation_data=(X_val, Y_val), steps_per_epoch=X_train.shape[0]//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WNzAAQ6uGSdX",
    "outputId": "efe251cc-07ac-4b31-d9ca-b6eb9b63d606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 50us/step\n",
      "Test loss: 0.0131 accuracy: 0.9949\n"
     ]
    }
   ],
   "source": [
    "#학습시킨 모델을 test data에 적용하여 일반화가 성공적으로 되었는지 확인합니다.\n",
    "#이 test accuracay가 0.99 이상이 되어야 합니다.\n",
    "test_loss, test_accuracy = \\\n",
    "  model.evaluate(X_test, Y_test, batch_size=64)\n",
    "print('Test loss: %.4f accuracy: %.4f' % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QOHkW0iTkVZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "99.66%.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
